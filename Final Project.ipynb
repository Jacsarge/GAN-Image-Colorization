{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final Project.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmEF_usr0i_E","outputId":"7c775c24-fafc-4032-fa2c-486fd67465c1"},"source":["!wget http://images.cocodataset.org/zips/train2017.zip\n","!unzip -q train2017.zip\n","\n","# !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","# !unzip -q annotations_trainval2017.zip\n","\n","#add val set? enough space in runtime?\n","#!wget http://images.cocodataset.org/zips/val2017.zip\n","#!unzip -q val2017.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-04-24 22:20:33--  http://images.cocodataset.org/zips/train2017.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.92.140\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.92.140|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19336861798 (18G) [application/zip]\n","Saving to: ‘train2017.zip.2’\n","\n","train2017.zip.2       0%[                    ]  81.51M   102MB/s               ^C\n","replace train2017/000000147328.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F_N2coNNzm79"},"source":["import torch\n","from torchvision import datasets\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hk4y4gIw0SR_","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1619152471190,"user_tz":420,"elapsed":4388,"user":{"displayName":"Nathan Martin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GglYaTmDXYbCYeIm6S3t0h_D73RzkX9hWGVrV_X=s64","userId":"08494715567763965026"}},"outputId":"f06465b7-7419-4fa7-e195-f2d741e71992"},"source":["train_dataset = datasets.CocoCaptions(\n","  root=\"./train2017\",\n","  annFile=\"./annotations/captions_train2017.json\",\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loading annotations into memory...\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8ae9ff5c759d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset = datasets.CocoCaptions(\n\u001b[1;32m      2\u001b[0m   \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./train2017\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mannFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./annotations/captions_train2017.json\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, annFile, transform, target_transform, transforms)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pycocotools/coco.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading annotations into memory...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annotation file format {} not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './annotations/captions_train2017.json'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ewau-ZGO0gHd","executionInfo":{"status":"ok","timestamp":1619117439553,"user_tz":240,"elapsed":818,"user":{"displayName":"Jackson Sargent","photoUrl":"","userId":"03766547292718414626"}},"outputId":"35aefb8b-d2f5-4433-ada4-edeab0741536"},"source":[""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset CocoCaptions\n","    Number of datapoints: 118287\n","    Root location: ./train2017"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"-3ZblZqBBh_o"},"source":["print('Number of samples: ', len(train_dataset))\n","img, target = train_dataset[3] # load 4th sample\n","\n","print(\"Image Size: \", img.size())\n","print(target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmJd25eG63WN"},"source":["from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLLXN1L5XPk_"},"source":["class ColorDataset(torch.utils.data.Dataset):\n","    def __init__(self, path, transform):\n","        self.path = path\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        img = Image.open(self.path[index]).convert(\"RGB\")\n","        img = self.transforms(img)\n","        img = np.array(img)\n","        img_lab = rgb2lab(img).astype(\"float32\")\n","        img_lab = transforms.ToTensor()(img_lab)\n","        L = img_lab[[0], ...] / 100.\n","        ab = img_lab[[1, 2], ...] / 110.\n","        \n","        return {'L': L, 'ab': ab}\n","\n","    def __len__(self):\n","        return len(self.path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8t_ZiTX-ZLZg"},"source":["img_transform = transforms.Resize((256, 256),  Image.BICUBIC)\n","\n","training_dataset = ColorDataset(path=\"./train2017\",transform=img_transform)\n","training_dataloader = torch.utils.data.DataLoader(dataset, batch_size=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiUSoi8UwBPP"},"source":[""],"execution_count":null,"outputs":[]}]}